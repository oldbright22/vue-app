<template>
  <div>
    <section id="setup-container" >
      <div class="setup-inner" width="850px">
        <img src="../assets/boss.png" alt="MovieBoss">
        <table border="1">
            <tr>
                <td>
                  <div class="speech-bubble-ai" ref="speechBubble">
                    <p ref="processingText">
                      Hi! My name is Tim. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Please share in a few words a topic, for which I'll give you an Advertising title and Image URL!
                    </p>
                  </div>
                </td>
            </tr>
            <tr>
                <td>
                  <div class="speech-bubble-ai" ref="speechBubble">
                    <p style="color: lightblue;" ref="adTitleText">
                      new title to generate....
                    </p>
                  </div>
                </td>
            </tr>
            <tr>
                <td>
                  <div class="speech-bubble-ai" ref="speechBubble">
                    <p style="font-size: 10px; color: lightslategray;" ref="adURLText">
                      new url image to be generate....
                    </p>
                  </div>  
                </td>
            </tr>
        </table>        
      </div>
      <div class="setup-inner setup-input-container" ref="setupInputContainer">
        <textarea v-model="userInput" id="setup-textarea" placeholder="Please enter one desired topic."></textarea>
        <button @click="submitSetup" class="send-btn" id="send-btn" aria-label="send">
          <img src="../assets/send-btn-icon.png" alt="send">
        </button>
      </div>
    </section>
    <section class="output-container" id="output-container">                 
    </section>
  </div>
</template>

<script setup>
  import { ref } from 'vue';
  import OpenAI from 'openai';
  
  const key='YOUR_OPEN_AI-KEY'

  const openai = new OpenAI({
  apiKey: key, // This is also the default, can be omitted
  dangerouslyAllowBrowser: true  //Enable this to able to make API calls - for testing prototype or trial an error
  }); 


  // Reactive Variables
  const userInput = ref("");
  const setupInputContainer = ref(null);
  const processingText = ref(null);
  const adTitleText = ref(null);
  const adURLText = ref(null);
  

  // Show Loading Indicator
  const showLoadingIndicator = () => {
    setupInputContainer.value.innerHTML = `<img src="../assets/loading.svg" class="loading" id="loading">`;
    processingText.value.innerText = `Ok, just wait a second while my digital brain digests that...`;
    adTitleText.value.innerText = `.. `;
    adURLText.value.innerText = `.. `;
  };


  // ------------------------------------------------------------------------------------------------
  // KICK START POINT: 
  //-------------------------------------------------------------------------------------------------
  // 1> User submits a input [userInput]
  // 
  // Following actions are auto-triggered in sequence and using [userInput] provided:
  //
  // 2> FETCHTITLE 
  //    A new Advertising Title its generated based on [userInput] provided
  //
  // 3> FETCHIMAGEPROMPT
  //    A new Short Image Description its generated based on [title] and [userInput] provided
  //    A new Image URL its generated per [Image Description] generated by the model
  //------------------------------------------------------------------------------------------------ 
  const submitSetup = () => {
    if (userInput.value) {
      
      //Initialize UI fields - notify end-user his/her request is under processing 
      showLoadingIndicator();
      
      //sequence of actions, auto-triggered per user input
      var title = fetchTitle(userInput.value);    
      fetchImagePrompt(title,userInput.value);

    //Below calls are not longer needed for the purpose of this exercise.  
    //fetchSynopsis(userInput.value);   -- Example of additional call to LLM with a more roboust effort - by creating a long synopsis 
    //fetchBotReply(userInput.value);   -- Example of additional call to LLM with a simple request to LLM  
   }
  };


  // Fetch Ad Title
  const fetchTitle = async (userInput) => {
    try {
     
      var titleFinished=" "

      // API Call to OpenAI for Ad Title
      const response = await openai.completions.create({
        model: 'gpt-3.5-turbo-instruct',
        prompt: `Generate a catchy advertising title for a product or service for input provided. Between 5 to 10 words: ${userInput}`,
        max_tokens: 25,
        temperature: 1.0, //more creative
      }).then(response => {
        console.log('TITLE Finished[' + response.choices[0].finish_reason + '] = ' + response.choices[0].text)
  
        titleFinished =  '[' + response.choices[0].finish_reason + '] = ' + response.choices[0].text
        adTitleText.value.innerText = titleFinished
        console.log('....');
        setTimeout(function(){
        console.log('timeout-end 1');
        },10000);
        
      });
      console.log(response)
    } catch (error) {
      if (error.response) {
          // The request was made and the server responded with a status code
          console.log(error.response.data);
          console.log(error.response.status);
          console.log(error.response.headers);
        } else if (error.request) {
          // The request was made but no response was received
          console.log(error.request);
        } else {
          // Something else happened during the request that triggered an error
          console.log('Error', error.message);
        }

    }
  };


  
  // Fetch Image Prompt and URL
  const fetchImagePrompt = async (title,userInput) => {
    try {
      // API Call to OpenAI for Image Prompt
      const response = await openai.completions.create({
        model: 'gpt-3.5-turbo-instruct',
        prompt: `Give a short description of an image that can be used to advertise a product or service based on title provided. The description should be rich in visual detail and should not exceed more than 20 words.
        ###
        title: ${title}
        userInput: ${userInput}
        image description: 
        `,
        temperature: 0.8,
        max_tokens: 50,
      }).then(response => {
        console.log('IMAGE DESCRIPTION Finish[' + response.choices[0].finish_reason + '] ' + response.choices[0].text.trim())
        console.log('.....');
        setTimeout(function(){
        console.log('timeout end 2');
        },10000);        
        fetchImageUrl(response.choices[0].text.trim())
      });
      console.log(response)

    } catch (error) {
      if (error.response) {
          // The request was made and the server responded with a status code
          console.log(error.response.data);
          console.log(error.response.status);
          console.log(error.response.headers);
        } else if (error.request) {
          // The request was made but no response was received
          console.log(error.request);
        } else {
          // Something else happened during the request that triggered an error
          console.log('Error', error.message);
        }

    }
  };


  // Fetch Image URL
  const fetchImageUrl = async (imagePrompt) => {
    try {
   
    console.log(imagePrompt);
    alert("IMAGE DESCRIPTION= "+imagePrompt)

    //By default, images are generated at "standard" quality, but when using DALL·E 3 
    //you can set quality: "hd" for enhanced detail. 
    //Square, standard quality images are the fastest to generate.

    // API Call to OpenAI for Image URL using DALL·E 3
    const response = await openai.images.generate({
        model: 'dall-e-3',
        prompt: `${imagePrompt}. Image should not have any text. Image is not cropped.`,
        n: 1,
        quality:'standard',
        size: '1024x1024',
        //response_format: 'b64_json',
      }).then(response => {
        console.log('Image URL = response.data', response.data)
        console.log('Generated Image URL: ',response.data[0].url)
        adURLText.value.innerText = response.data[0].url
        //imageUrl.value = `data:image/png;base64,${response.data[0].b64_json}`;
        console.log('....');
        setTimeout(function(){
        console.log('timeout end 3');
        },10000);
      });

    
      console.log(response)
    } catch (error) {

        if (error.response) {
          // The request was made and the server responded with a status code
          console.log(error.response.data);
          console.log(error.response.status);
          console.log(error.response.headers);
        } else if (error.request) {
          // The request was made but no response was received
          console.log(error.request);
        } else {
          // Something else happened during the request that triggered an error
          console.log('Error', error.message);
        }
    }
  };


  /*
  // Fetch Synopsis
  const fetchSynopsis = async (outline) => {
    try {
      var synopsis = " ";
      // API Call to OpenAI for Synopsis
      const response = await openai.completions.create({
        model: 'gpt-3.5-turbo-instruct',
        prompt: `Generate an engaging, professional and marketable movie synopsis based on an outline. 
        The synopsis should include actors names in brackets after each character. 
        Choose actors that would be ideal for this role. 
        ###
        outline: ${outline}
        synopsis: 
        `,
        max_tokens: 700,
      }).then(response => {
        console.log('Finish[' + response.choices[0].finish_reason + '] ' + response.choices[0].text.trim());
        console.log('....');
        setTimeout(function(){
        console.log('timeout ended');
        },10000);
        synopsis = response.choices[0].text.trim();
        //alert(synopsis)
      });

      console.log(response)
      return synopsis

     //await fetchTitle(synopsis);
     //await fetchStars(synopsis);

    } catch (error) {
      console.error('[Fetch Synopsis] ERROR:', error);
      // Handle errors as needed
    } 
  };
  
  // Fetch Cast Stars
  const fetchStars = async (synopsis) => {
    try {
      
      // API Call to OpenAI for Cast Stars
      const response = await openai.completions.create({
        model: 'gpt-3.5-turbo-instruct',
        prompt: `Extract the names in brackets from the synopsis.
        ###
        synopsis: ${synopsis}
        names:   
        `,
        max_tokens: 30,
      }).then(response => {
        console.log(response.choices[0].text.trim())
        console.log(response.choices[0].finish_reason)
        console.log(response.choices)
        //processingText.value.innerText = 'Finish[' + response.choices[0].finish_reason + '] ' + response.choices[0].text.trim();
        console.log('....');
        setTimeout(function(){
        console.log('timeout end');
        },5000);
      });
      console.log(response)

    } catch (error) {
      console.error('[Fetch Stars] ERROR :', error);
      // Handle errors as needed
    }
  };

// FetchBot Reply
  const fetchBotReply = async (outline) => {
    try {      
    
      //API Call to OpenAI for Bot Reply
      const response = await openai.completions.create({
      model: 'gpt-3.5-turbo-instruct', 
      prompt: `Generate a short message that talks enthusiastically about outline and sounds interesting.
        ###
        outline: ${outline}
        message: 
        `,
      temperature: 0.8,
      max_tokens: 60
      }).then(response => {
        console.log('REPLY BOT Finish[' + response.choices[0].finish_reason + '] ' + response.choices[0].text.trim())
        console.log('.....');
        setTimeout(function(){
        console.log('timeout end..');
        },5000);
      });
      console.log(response)

    } catch (error) {
      if (error.response) {
          // The request was made and the server responded with a status code
          console.log(error.response.data);
          console.log(error.response.status);
          console.log(error.response.headers);
        } else if (error.request) {
          // The request was made but no response was received
          console.log(error.request);
        } else {
          // Something else happened during the request that triggered an error
          console.log('Error', error.message);
        }

    } 
  };

  */
 
</script>

<style scoped>

section {
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  background-color: var(--light);
  border-radius: var(--border-rad-lg);
  padding: 16px;
  box-shadow: 0px 1px 18px 3px var(--dark);
  max-width: 750px;
  width: calc(100% - 32px);
  z-index: 1000;
}

/* Setup */

.setup-inner {
  display: flex;
  justify-content: space-around;
  padding: 24px 8px;
  min-height: 234px;
}

.setup-inner>img {
  width: 50%;
  filter: drop-shadow(3px 2px 3px var(--medium-dark));
  align-self: center;
}

.setup-input-container {
  min-height: 74px;
}

.speech-bubble-ai {
  max-width: 90%;
  min-height: 124px;
  border-radius: var(--border-rad-lg);
  position: relative;
  margin: 0;
  border: 3px solid var(--medium-dark);
  background-color: var(--white);
  align-self: flex-start;
  display: flex;
  align-items: center;
}

.speech-bubble-ai:before {
  content: "";
  position: absolute;
  border-left: 9px solid transparent;
  border-right: 9px solid var(--medium-dark);
  border-top: 9px solid var(--medium-dark);
  border-bottom: 9px solid transparent;
  left: -21px;
  top: 64px;
}

.speech-bubble-ai:after {
  content: "";
  position: absolute;
  border-left: 7px solid transparent;
  border-right: 7px solid var(--white);
  border-top: 7px solid var(--white);
  border-bottom: 7px solid transparent;
  left: -11px;
  top: 68px;
}

.speech-bubble-ai>p {
  padding: 0 1.3em;
  color: var(--dark);
  font-size: 14px;
}

textarea {
  background-color: var(--light-grey);
  padding: 8px;
  border: none;
  border-top-right-radius: 0;
  border-top-left-radius: var(--border-rad-lg);
  border-bottom-right-radius: 0;
  border-bottom-left-radius: var(--border-rad-lg);
  width: 100%;
  resize: none;
  min-height: 40px;
  box-sizing: border-box;
  font-family: 'Poppins', sans-serif;
}

textarea::placeholder {
  color: var(--medium-dark);
  font-size: 14px;
  opacity: 0.8;
}

/* Larger mobiles+ */
@media(min-width: 380px) {
  .setup-input-container {
    padding-top: 0;
  }

  .speech-bubble-ai:before {
    top: 92px;
  }

  .speech-bubble-ai:after {
    top: 96px;
  }

  .speech-bubble-ai>p {
    font-size: 16px;
  }

  textarea::placeholder {
    font-size: 16px;
    opacity: 0.8;
  }
}

/* Buttons & SVG */
button {
  border: none;
  background: var(--pink);
  cursor: pointer;
}

button:hover {
  background-color: var(--dark);
}

.send-btn {
  border-top-right-radius: var(--border-rad-lg);
  border-bottom-right-radius: var(--border-rad-lg);
  min-width: 50px;
}

.send-btn>img {
  width: 1.6em;
  vertical-align: middle;
}

.view-pitch-btn {
  color: var(--light);
  border-radius: var(--border-rad-lg);
  padding: 16px;
  margin: 4px auto;
  display: block;
  font-size: 18px;
}

.view-pitch-btn:hover {
  box-shadow: 1px 1px 5px 1px var(--medium-dark);
}

img.loading {
  max-width: 50px;
  filter: none;
}

/* Output */
.output-container {
  display: none;
  flex-direction: column;
  margin: 16px auto;
  color: var(--dark);
  padding: 16px;
}

.output-img-container>img {
  width: 90%;
  border-radius: var(--border-rad-lg);
  box-shadow: 2px 2px 6px 2px var(--dark);
}

</style>
